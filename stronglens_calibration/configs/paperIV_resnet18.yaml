# Paper IV Parity: Standard ResNet-18
# ~11.2M params (larger than Paper IV's 194K, but standard and defensible)
# Protocol: 160 epochs, StepLR halve@80, effective batch 2048, unweighted CE, 101x101
# Date: 2026-02-11

dataset:
  parquet_path: ""
  manifest_path: /lambda/nfs/darkhaloscope-training-dc/stronglens_calibration/manifests/training_parity_70_30_v1.parquet
  mode: file_manifest
  preprocessing: raw_robust
  label_col: label
  cutout_path_col: cutout_path
  sample_weight_col: sample_weight
  seed: 42
  crop: false           # Keep 101x101 for Paper IV parity
  crop_size: 0

augment:
  hflip: true
  vflip: true
  rot90: true

train:
  arch: resnet18
  epochs: 160
  batch_size: 128         # Micro-batch
  effective_batch: 2048   # 2048/128 = 16 accumulation steps
  lr: 0.0005              # 5e-4
  weight_decay: 0.0001
  lr_schedule: step
  lr_step_epoch: 80
  lr_gamma: 0.5
  num_workers: 8
  device: cuda
  early_stopping_patience: 0   # Run all 160 epochs
  out_dir: /lambda/nfs/darkhaloscope-training-dc/stronglens_calibration/checkpoints/paperIV_resnet18
  mixed_precision: true
  unweighted_loss: true
  pretrained: false
