\documentclass[fleqn,usenatbib]{mnras}

\usepackage[T1]{fontenc}
\usepackage{newtxtext,newtxmath}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{hyperref}

\title[Injection realism gap for CNN lens finding]{The morphological barrier: quantifying the injection realism gap for CNN strong lens finders in DESI Legacy Survey DR10}

\author[Author et al.]{
A.~Author,$^{1}$\thanks{E-mail: author@institute.edu}
B.~Author,$^{2}$
C.~Author$^{1}$
\\
$^{1}$Institute, Address\\
$^{2}$Institute, Address
}

\date{Accepted XXX. Received YYY; in original form ZZZ}
\pubyear{2026}

\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

% ====================================================================
% ABSTRACT
% ====================================================================
\begin{abstract}
We present a quantitative measurement of the gap between real gravitational lens morphology and parametric injection models in the learned feature space of a convolutional neural network (CNN) lens finder, together with a controlled experiment that diagnoses its origin.  Our EfficientNetV2-S classifier, trained on 451\,681 cutouts from the DESI Legacy Imaging Survey DR10 ($g/r/z$ bands, $101\times101$ pixels at $0.262\;\mathrm{arcsec\;pixel^{-1}}$), achieves $89.3$ per cent recall (95 per cent Wilson CI: $[82.6, 94.0]$ per cent) on 112 spectroscopically confirmed lenses held out from training, with zero Tier-A HEALPix pixel overlap between training and validation sets.

Standard injection-recovery using parametric S\'{e}rsic source profiles lensed by a singular isothermal ellipsoid yields a marginal completeness of only $3.41$ per cent ($3755/110\,000$) over the full parameter space, which is dominated by faint ($m_{\rm lensed} > 22$) configurations.  Even when restricted to bright, favourably lensed injections at magnitudes comparable to real confirmed lenses ($m_{\rm lensed} = 19\text{--}22$), detection rates reach only $18$--$36$ per cent --- a factor of $2$--$5$ below the Tier-A recall.  A linear probe (logistic regression) trained on the CNN's penultimate 1280-dimensional features separates real lenses from brightness-matched injections with AUC $= 0.996 \pm 0.004$ (five-fold cross-validation), indicating that the deficit reflects a strong feature-space separation that persists beyond brightness differences, consistent with a morphological mismatch between parametric and real arc morphology (though host-galaxy population differences may also contribute; see Section~5.4).

We test the hypothesis that this gap arises from missing pixel-level noise texture by adding physically motivated Poisson shot noise to injected arcs.  Adding arc-level Poisson noise --- using an approximate effective gain of $\sim\!150\;\mathrm{e^{-}\;nmgy^{-1}}$ for DR10 coadds --- \emph{degrades} detection from $3.41$ to $2.37$ per cent (two-proportion $z = 14.6$, $p < 10^{-47}$).  A control experiment at gain $= 10^{12}$ (negligible Poisson noise) recovers the no-noise baseline exactly, confirming the implementation is correct and the degradation is physical.  The per-pixel photoelectron budget predicts this result: for the faint arcs dominating the grid (lensed magnitude $\gtrsim 23$, flux $\lesssim 0.6\;\mathrm{nmgy}$), each arc pixel has $\sim\!1$ photoelectron at gain $150\;\mathrm{e^{-}\;nmgy^{-1}}$, making shot noise comparable to the signal.

These results demonstrate that adding arc-level shot noise alone does not close the sim-to-real gap, and indicate that morphological realism (source substructure, colour morphology, correlated noise, and PSF fidelity) is the limiting factor for parametric injection-recovery in ground-based data.  We provide completeness maps as characterised lower bounds under the parametric injection model and propose linear-probe AUC as a practical realism gate for injection pipelines.
\end{abstract}

\begin{keywords}
gravitational lensing: strong -- methods: data analysis -- methods: statistical -- surveys -- techniques: image processing
\end{keywords}


% ====================================================================
% 1. INTRODUCTION
% ====================================================================
\section{Introduction}

The population statistics of galaxy-scale strong gravitational lenses encode the mass structure of galaxies and the geometry of the Universe \citep[e.g.][]{Treu2010,Collett2015}.  Measuring the strong lens population function --- the number density of lenses as a function of Einstein radius, source redshift, and survey selection --- requires an accurate selection function: the probability that a lens of given properties is detected by the survey pipeline \citep{Collett2015,Sonnenfeld2022}.  Selection function calibration is typically performed via \emph{injection-recovery}, in which synthetic lensed sources are injected into real survey images and processed through the same detection pipeline used for science \citep[e.g.][]{Gavazzi2014,Jacobs2019,CollettCunnington2022}.

The advent of convolutional neural network (CNN) lens finders has transformed strong lens discovery.  Modern CNNs achieve high recall on confirmed lenses \citep{Petrillo2017,Lanusse2018,Jacobs2019,Metcalf2019,Huang2020,Canameras2021,Savary2022,Stein2022,Rojas2022,Storfer2024} and have produced large candidate catalogues from wide-area surveys.  However, the question of how to calibrate their selection functions remains open.  The standard approach uses parametric source models --- typically S\'{e}rsic profiles lensed by singular isothermal ellipsoids (SIE) or singular isothermal spheres (SIS) with external shear --- to generate synthetic lensed arcs for injection \citep[e.g.][]{CollettCunnington2022,Herle2024}.  This approach assumes that parametric models capture the morphological features that the CNN uses for detection.

Recent work has begun to question this assumption.  \citet{Herle2024} characterised selection biases in CNN lens finders trained on simulated Euclid-like data, demonstrating that detection depends strongly on Einstein radius, source S\'{e}rsic index, and source size.  Their analysis was performed entirely in simulation, without comparison to real confirmed lenses.  \citet{Canameras2024} (HOLISMOKES~XI) took a different approach for the Hyper Suprime-Cam (HSC) survey, using real galaxy stamps from the Hubble Ultra Deep Field (HUDF) as source-plane objects rather than parametric models \citep[see also][for the simulation methodology]{Canameras2021}.  They explicitly noted the inadequacy of S\'{e}rsic profiles, though they did not quantify the gap.  Neither study measured the discrepancy between real and injected lenses directly in CNN feature space.

In this work, we provide the first measurement of this discrepancy directly in CNN feature space, combined with a controlled diagnostic experiment.  We train an EfficientNetV2-S lens finder on DESI Legacy Imaging Survey DR10 data and compare its internal representations of 112 spectroscopically confirmed (Tier-A) lenses against parametric S\'{e}rsic injections.  A linear probe achieves AUC $= 0.996$ separating the two populations, establishing that the CNN has learned to distinguish real from injected lenses in its penultimate feature space.  We then conduct a controlled experiment to diagnose the cause of this gap.

Our central experimental contribution is a controlled Poisson noise test.  If the injection realism gap were caused by missing pixel-level noise texture --- real arcs have shot noise proportional to their flux, while parametric injections are anomalously smooth --- then adding physically correct Poisson noise should improve detection.  We find the opposite: Poisson noise \emph{degrades} detection, from $3.41$ to $2.37$ per cent marginal completeness.  A gain sweep control confirms the implementation is correct.  We conclude that the barrier is morphological: parametric S\'{e}rsic profiles are too smooth to activate the same CNN features as real lensed galaxies, regardless of noise texture.

This work makes four contributions:
\begin{enumerate}
\item A quantitative measurement of the injection realism gap for a CNN lens finder on ground-based survey cutouts: even for brightness-matched injections at lensed magnitudes $19$--$22$, detection rates reach only $18$--$36$ per cent versus $89.3$ per cent Tier-A recall ($3.41$ per cent when averaged over the full parameter space).
\item A controlled test showing that adding arc-level Poisson shot noise does not close the gap --- and in fact widens it --- verified by a gain-sweep control that confirms the code path is correct.
\item A feature-space diagnostic of injection realism: a linear probe on penultimate CNN features separates real lenses from injections with AUC $0.996 \pm 0.004$.
\item A rigorously characterised completeness map for the specific parametric injection family, together with a diagnostic framework (linear-probe AUC) to assess and iteratively improve injection realism.
\end{enumerate}

Throughout this paper, we distinguish between \emph{morphological} realism (the spatial organisation and substructure of the source-plane light after lensing: clumps, spiral arms, caustic crossings, multiple images) and \emph{textural} realism (pixel-scale noise properties and instrumental signatures: shot noise, correlated noise, PSF wings).  We structure the paper as a diagnostic ladder: establish the gap, propose a plausible textural explanation (missing shot noise), test it with a controlled experiment and gain-sweep control, and draw the minimal conclusion supported by the data.  Section~2 describes the survey data and CNN architecture.  Section~3 details the injection pipeline.  Section~4 presents the sim-to-real gap and the controlled Poisson noise experiment.  Section~5 discusses implications and comparisons with published work.  Section~6 summarises our conclusions.  Appendix~\ref{app:annulus} characterises the annulus normalisation.


% ====================================================================
% 2. DATA AND MODEL
% ====================================================================
\section{Data and model}

\subsection{DESI Legacy Imaging Survey DR10}

We use $g$-, $r$-, and $z$-band imaging from the tenth data release (DR10) of the DESI Legacy Imaging Surveys \citep{Dey2019}.  The survey covers approximately 14\,000~deg$^{2}$ in three optical bands at a native pixel scale of $0.262\;\mathrm{arcsec\;pixel^{-1}}$.  Typical $5\sigma$ point-source depths are $g \approx 24.7$, $r \approx 23.9$, and $z \approx 23.0$~mag (AB).  The median delivered seeing in $r$ band is approximately $1.3\;\mathrm{arcsec}$ FWHM.

For each object in the training catalogue, we extract $101 \times 101$ pixel cutouts ($26.5 \times 26.5\;\mathrm{arcsec}^{2}$) centred on the Tractor catalogue position.  Cutouts are stored in nanomaggy units (AB zeropoint 22.5) as three-channel images ($g$, $r$, $z$).

\subsection{Training data}

The training set comprises 451\,681 cutouts divided into 316\,100 training and 135\,581 validation samples via a spatial split based on HEALPix pixels (NSIDE $= 128$).  The positive class consists of 277 Tier-A (spectroscopically confirmed) and 3079 Tier-B (visual candidates) strong lenses, with geometric augmentation applied stochastically during training (see Table~\ref{tab:dataset}).  The negative class consists of approximately 135\,000 non-lens cutouts per split, drawn from the Tractor catalogue with magnitude and colour cuts designed to include the full range of galaxy morphologies.

\begin{table}
\caption{Training set composition.  All counts are unique base cutouts.  Geometric augmentation (horizontal flip, vertical flip, random $90\degr$ rotation) is applied stochastically during training and does not change the manifest size.}
\label{tab:dataset}
\centering
\begin{tabular}{lccc}
\toprule
 & Training & Validation & Total \\
\midrule
Tier-A positives & 277 & 112 & 389 \\
Tier-B positives & 3\,079 & 1\,320 & 4\,399 \\
Total positives & 3\,356 & 1\,432 & 4\,788 \\
Negatives & 312\,744 & 134\,149 & 446\,893 \\
\midrule
Total & 316\,100 & 135\,581 & 451\,681 \\
\bottomrule
\end{tabular}
\end{table}

The Tier-A sample comprises lenses with spectroscopic confirmation of multiple redshifts from SDSS, DESI, and targeted follow-up campaigns.  The Tier-B sample comprises visually identified candidates from citizen science and expert inspection without spectroscopic confirmation; we estimate approximately 10~per cent label noise in this tier.  We emphasise that our headline recall metric (Section~4.1) is evaluated exclusively on Tier-A lenses in the validation split.

\subsection{Spatial integrity}

To verify that training and validation sets are spatially disjoint, we recomputed HEALPix pixel assignments for all positives (a manifest-generation issue had left the HEALPix column as NaN for positives).  The result: Tier-A training and validation sets occupy 274 and 112 unique HEALPix pixels respectively, with zero overlapping pixels.  This confirms that the model has not seen sky regions near any validation Tier-A lens during training.

\subsection{Architecture and training}

We use EfficientNetV2-S \citep{TanLe2021}, a 20.2~million parameter architecture pretrained on ImageNet-1K.  Training proceeds in two phases.  Phase~1 initialises from ImageNet weights and trains for 160 epochs with a step learning rate schedule (initial LR $= 3.88 \times 10^{-4}$, from preliminary hyperparameter search; decay by $0.5$ at epoch 130).  The best validation AUC (0.9915) is reached at epoch~19.  Phase~2 loads the epoch-19 weights and fine-tunes for 60 epochs with cosine learning rate decay from $5 \times 10^{-5}$, reaching a final best validation AUC of 0.9921.

Training uses unweighted binary cross-entropy loss, a micro-batch size of 64 accumulated to an effective batch size of 512, mixed-precision (float16) forward passes, and geometric augmentation (horizontal flip, vertical flip, $90\degr$ rotation) applied to all cutouts (both positives and negatives).  The positive-to-negative class ratio in the manifest is approximately $1{:}93$.  We chose unweighted loss because overweighting the small positive class risks overfitting to Tier-B label noise ($\sim\!10$~per cent of Tier-B may be non-lenses).  We did not apply noise or colour augmentation during training; this means the model has not seen Poisson-noised injections during training, which is relevant to interpreting the Poisson experiment (Section~4.4): the degradation from Poisson noise reflects a distribution shift relative to both the training data and the no-noise injections, not merely relative to the training data.

\subsection{Preprocessing}
\label{sec:preprocessing}

Each cutout is preprocessed in the \texttt{raw\_robust} mode: for each band independently, the pixel values are (i) centred by subtracting the median of an outer annulus of pixels, and (ii) scaled by dividing by the median absolute deviation (MAD) of the same annulus.  Specifically, for a $101 \times 101$ image with annulus inner radius $r_{\rm in} = 20$~pixels and outer radius $r_{\rm out} = 32$~pixels, the normalised image is
\begin{equation}
x_{\rm norm} = \frac{x - \mathrm{median}(x_{\rm annulus})}{\mathrm{MAD}(x_{\rm annulus})}
\end{equation}
where $\mathrm{MAD}(x) = \mathrm{median}(|x - \mathrm{median}(x)|)$ is the raw (unscaled) median absolute deviation, followed by clipping to $[-10, +10]$.  This places sky-dominated pixels near zero with unit noise scale, while central galaxy and arc features appear as positive excursions of several normalised units.

We note that the annulus radii $(20, 32)$ were originally tuned for $64 \times 64$ stamps.  For the $101 \times 101$ stamps used here, this annulus sits at $40$--$64$~per cent of the image half-width, partially overlapping with extended galaxy light.  The geometrically optimal radii for $101 \times 101$ stamps are $(32.5, 45.0)$.  Appendix~\ref{app:annulus} demonstrates that this discrepancy produces a $0.15$-normalised-unit additive offset in the median while leaving the MAD (and hence the signal-to-noise structure) unchanged.  The effect is cosmetic for model performance; we retain the training-consistent annulus for all analyses.


% ====================================================================
% 3. INJECTION PIPELINE
% ====================================================================
\section{Injection pipeline}

\subsection{Lens model}

We adopt a singular isothermal ellipsoid \citep[SIE;][]{Kormann1994} with external shear.  The deflection angles are computed via the standard analytical formulae \citep{Keeton2001}, with a branch for the spherical limit ($q \to 1$) to avoid numerical singularity.

The lens parameters are drawn as follows.  The Einstein radius $\theta_{\rm E}$ is specified per experiment (fixed at $1.5\;\mathrm{arcsec}$ for bright-arc tests; gridded over $[0.5, 3.0]\;\mathrm{arcsec}$ in $0.25\;\mathrm{arcsec}$ steps for the completeness grid).  The lens axis ratio is drawn from $q_{\rm lens} \sim \mathcal{U}(0.5, 1.0)$.  The position angle is drawn from $\phi_{\rm lens} \sim \mathcal{U}(0, \pi)$.  External shear components are drawn from $(\gamma_1, \gamma_2) \sim \mathcal{N}(0, 0.05)$.  The lens centre is jittered by $(\Delta x, \Delta y) \sim \mathcal{N}(0, 0.05\;\mathrm{arcsec})$.

\subsection{Source model}

The source is modelled as a S\'{e}rsic \citep{Sersic1968} profile, using the $b_n$ approximation of \citet{CiottiBertin1999}, with optional Gaussian clumps.  The source $r$-band magnitude is drawn from $m_r \sim \mathcal{U}(23, 26)$ for the grid (extended to $\mathcal{U}(18, 26)$ for bright-arc tests).  The S\'{e}rsic index is drawn from $n \sim \mathcal{U}(0.5, 4.0)$, effective radius from $R_{\rm e} \sim \mathcal{U}(0.05, 0.50)\;\mathrm{arcsec}$, and axis ratio from $q \sim \mathcal{U}(0.3, 1.0)$.  Colours are drawn from $g - r \sim \mathcal{N}(0.2, 0.25)$ and $r - z \sim \mathcal{N}(0.1, 0.25)$.

The source position is parameterised by $\beta_{\rm frac} = \beta / \theta_{\rm E}$, drawn with area weighting: $\beta_{\rm frac} = \sqrt{\mathcal{U}(\beta_{\rm lo}^{2}, \beta_{\rm hi}^{2})}$ where the default range is $[\beta_{\rm lo}, \beta_{\rm hi}] = [0.1, 1.0]$.  The restricted tests use $[0.1, 0.55]$ to isolate configurations producing high-magnification arcs.

With 60~per cent probability, $1$--$4$ Gaussian clumps are added to the source profile.  Each clump is drawn from a Gaussian centred within $\sim\! 0.6\,R_{\rm e}$ of the source centre, with the clump flux fraction drawn from $\mathcal{U}(0.15, 0.45)$.  The clumps are phenomenological perturbations intended to break the smooth symmetry of the S\'{e}rsic profile; they do not represent a physical model of star-forming regions.

\subsection{Ray-tracing and flux calibration}

For each injection, the lens equation $\boldsymbol{\beta} = \boldsymbol{\theta} - \boldsymbol{\alpha}_{\rm SIE}(\boldsymbol{\theta}) - \boldsymbol{\alpha}_{\rm shear}(\boldsymbol{\theta})$ is evaluated on a sub-pixel grid at $4\times$ oversampling (i.e.\ $404 \times 404$ sub-pixels per cutout).  The source surface brightness is evaluated at the ray-traced source-plane position and block-averaged to the native pixel scale.  Per-band PSF convolution is performed via FFT with a Gaussian kernel whose FWHM is taken from the host cutout's Tractor catalogue \texttt{psfsize\_r} value.  The $g$- and $z$-band PSFs are scaled by factors of 1.05 and 0.94 relative to $r$, respectively, approximating the typical chromatic seeing variation.

Flux is calibrated in nanomaggies.  The source profile is normalised by its analytical S\'{e}rsic source-plane integral \citep{GrahamDriver2005}, so that the image-plane flux equals the magnification-corrected unlensed flux.  This ensures correct flux conservation under lensing.

\subsection{Poisson noise}

Real lensed arcs contribute Poisson (shot) noise proportional to $\sqrt{N_{\rm e}}$, where $N_{\rm e}$ is the number of photoelectrons per pixel.  Parametric injections omit this noise, making bright injections anomalously smooth --- a statistical signature potentially detectable by a CNN trained on real data.

To test this hypothesis, we optionally add Poisson noise to the injected arc signal.  For injection flux $I$ (nanomaggies) and gain $g$ (electrons per nanomaggy),
\begin{equation}
E = g\,\max(I, 0), \quad E' \sim \mathrm{Poisson}(E), \quad I_{\rm poiss} = I + \frac{E' - E}{g} .
\label{eq:poisson}
\end{equation}
We use $g = 150\;\mathrm{e^{-}\;nmgy^{-1}}$ as an approximate DR10 coadd gain.  Zero-flux pixels satisfy $\mathrm{Poisson}(0) = 0$, so no noise is injected into sky-only regions.  The implementation in our injection engine is:
\begin{verbatim}
arc_electrons = injection.clamp(min=0.0)
                * gain_e_per_nmgy
noisy_electrons = torch.poisson(arc_electrons)
noise_electrons = noisy_electrons - arc_electrons
injection = injection
            + noise_electrons / gain_e_per_nmgy
\end{verbatim}

The gain of $150\;\mathrm{e^{-}\;nmgy^{-1}}$ is an order-of-magnitude estimate for a typical DR10 $r$-band coadd of $\sim\!30$ exposures at $90\;\mathrm{s}$ each.  We do not claim this is exact; instead, we use a gain sweep experiment (Section~\ref{sec:gainsweep}) to demonstrate that the result is physical and not an artifact of gain miscalibration.

\subsection{Host galaxies and injection procedure}

Host galaxies are drawn from the validation-split negative population of the training manifest.  For the bright-arc tests, 200 hosts are drawn with fixed seed ($= 42$) and reused across all magnitude bins and experimental conditions, creating a \emph{paired} design (Section~\ref{sec:brightarc}).  For the completeness grid, hosts are matched to grid cells by PSF FWHM, depth, and sky region, with up to 20\,000 unique hosts and 500 injections per non-empty cell (seed $= 1337$).

The injected arc is added to the host cutout in nanomaggy space \emph{before} preprocessing.  This ensures the injection experiences the same annulus normalisation and clipping as real features in the host.  The injection procedure adds simulated arc flux to a real DR10 host cutout; therefore, the injected images already contain the survey's background and host-galaxy noise and artefacts.  The hypothesised missing texture is primarily the shot noise associated with the added arc flux itself.


% ====================================================================
% 4. THE INJECTION REALISM GAP
% ====================================================================
\section{The injection realism gap}

\subsection{Real lens performance}

We score all 112 Tier-A lenses in the validation split using the frozen trained model.  Table~\ref{tab:tierA} presents the recall at multiple detection thresholds with 95~per cent Wilson score confidence intervals.

\begin{table}
\caption{Recall on 112 spectroscopically confirmed (Tier-A) lenses in the validation split.  Wilson 95~per cent confidence intervals account for the binomial sampling distribution.  FPR-derived thresholds are calibrated on 50\,000 validation negatives in the grid experiments; the empirical FPR on the 3000 negatives scored here is shown in parentheses.}
\label{tab:tierA}
\centering
\begin{tabular}{lccc}
\toprule
Threshold & Recall & $n_{\rm det}/112$ & 95\% Wilson CI \\
\midrule
$p > 0.3$ & 89.3\% & 100/112 & [82.6\%, 94.0\%] \\
$p > 0.5$ & 83.9\% & 94/112 & [76.3\%, 89.8\%] \\
$p > 0.806$ (FPR $\approx 10^{-3}$) & 79.5\% & 89/112 & [71.3\%, 86.1\%] \\
$p > 0.995$ (FPR $\approx 3 \times 10^{-4}$) & 48.2\% & 54/112 & [39.1\%, 57.4\%] \\
\bottomrule
\end{tabular}
\end{table}

The model achieves $89.3$~per cent recall at $p > 0.3$, declining to $48.2$~per cent at the stringent FPR $\approx 3 \times 10^{-4}$ threshold.  The median score for Tier-A lenses is 0.995, placing the vast majority of confirmed lenses in the high-confidence tail of the score distribution.  Twelve Tier-A lenses are missed at $p > 0.3$ (10.7~per cent of the sample).  A detailed characterisation of their properties --- host morphology, estimated Einstein radius, PSF FWHM, and depth --- is in preparation as part of a companion analysis.  Understanding these failure modes is essential for assessing whether the $89.3$~per cent recall is robust across the full diversity of lens configurations.

\subsection{Injection completeness is unexpectedly low}

We measure injection-recovery completeness on a three-dimensional grid spanning Einstein radius ($\theta_{\rm E} \in [0.50, 3.00]\;\mathrm{arcsec}$, 11 steps), PSF FWHM ($\mathrm{FWHM} \in [0.9, 1.8]\;\mathrm{arcsec}$, 7 steps), and $5\sigma$ depth ($\mathrm{depth} \in [22.5, 24.5]\;\mathrm{mag}$, 5 steps), for a total of 385 cells.  Of these, 220 cells contain matched host galaxies and 165 are empty (no hosts with the required observing conditions).  Each non-empty cell receives 500 injections with source magnitude drawn from $\mathcal{U}(23, 26)$ and all other source and lens parameters drawn from the priors of Section~3.

At a detection threshold of $p > 0.3$, the marginal completeness is $3.41$~per cent ($3755 / 110\,000$; 95~per cent Wilson CI $[3.30\%, 3.52\%]$).  This low figure is driven by the broad parameter space: $72$~per cent of injections have lensed magnitude $> 22$, where detection is intrinsically difficult.  At brighter magnitudes comparable to confirmed lenses ($m_{\rm lensed} = 20\text{--}22$), completeness rises to $20.7$~per cent --- still substantially below the $89.3$~per cent Tier-A recall.  The direct comparison is not straightforward because Tier-A lenses are a highly selected sample (bright, dramatically lensed, spectroscopically confirmed), but the gap persists even when comparing brightness-matched subsets, as we demonstrate in Section~4.3 using the linear probe.  Table~\ref{tab:thresholds} presents the completeness at all thresholds for both the baseline and Poisson conditions.

\begin{table}
\caption{Injection-recovery completeness over the full grid ($110\,000$ injections across 220 non-empty cells) at multiple detection thresholds.  The Poisson column adds shot noise at gain $= 150\;\mathrm{e^{-}\;nmgy^{-1}}$.}
\label{tab:thresholds}
\centering
\begin{tabular}{lccc}
\toprule
Threshold & No Poisson & Poisson & Deficit \\
\midrule
$p > 0.3$ & 3.41\% & 2.37\% & $-$1.04~pp \\
$p > 0.5$ & 2.75\% & 1.80\% & $-$0.95~pp \\
$p > 0.7$ & 2.26\% & 1.37\% & $-$0.89~pp \\
FPR $= 10^{-3}$ & 1.98\% & 1.18\% & $-$0.80~pp \\
FPR $= 10^{-4}$ & 0.55\% & 0.25\% & $-$0.30~pp \\
\bottomrule
\end{tabular}
\end{table}

Completeness depends strongly on both $\theta_{\rm E}$ and lensed apparent magnitude.  Table~\ref{tab:thetaE} presents the completeness by Einstein radius for the no-Poisson baseline.  Peak completeness occurs at $\theta_{\rm E} \approx 2.0\;\mathrm{arcsec}$ ($4.66$~per cent), declining at both ends --- small arcs are unresolved, while large arcs are spread over too many pixels to exceed the detection threshold against host-galaxy backgrounds.  Completeness rises steeply with lensed apparent magnitude: $48.8$~per cent for mag~$18$--$20$ (though only 41 injections fall in this bin), $20.7$~per cent for mag~$20$--$22$, $1.55$~per cent for mag~$22$--$24$ (which dominates the grid volume), and $0.34$~per cent for mag~$24$--$27$.

\begin{table}
\caption{Injection-recovery completeness by Einstein radius (no Poisson, $p > 0.3$).  Each $\theta_{\rm E}$ bin contains 10\,000 injections across all PSF and depth cells.}
\label{tab:thetaE}
\centering
\begin{tabular}{lcc}
\toprule
$\theta_{\rm E}$ (arcsec) & $C(p>0.3)$ & $n_{\rm det}/n_{\rm inj}$ \\
\midrule
0.50 & 0.44\% & 44/10\,000 \\
0.75 & 1.22\% & 122/10\,000 \\
1.00 & 2.57\% & 257/10\,000 \\
1.25 & 3.61\% & 361/10\,000 \\
1.50 & 4.33\% & 433/10\,000 \\
1.75 & 4.58\% & 458/10\,000 \\
2.00 & 4.66\% & 466/10\,000 \\
2.25 & 4.44\% & 444/10\,000 \\
2.50 & 4.32\% & 432/10\,000 \\
2.75 & 4.10\% & 410/10\,000 \\
3.00 & 3.28\% & 328/10\,000 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{fig1_completeness.pdf}
\caption{Injection-recovery completeness at $p > 0.3$.  \textbf{Left:} Completeness versus Einstein radius (no Poisson baseline), showing peak completeness at $\theta_{\rm E} \approx 2.0\;\mathrm{arcsec}$ with decline at both small (unresolved) and large (spread) radii.  Error bars show 95~per cent Wilson confidence intervals.  \textbf{Right:} Completeness versus lensed apparent magnitude in four bins ($18$--$20$, $20$--$22$, $22$--$24$, $24$--$27$), with both no-Poisson (blue) and Poisson (orange) conditions.  Data from the verified re-evaluation described in Data Availability.}
\label{fig:completeness}
\end{figure*}

\subsection{The CNN distinguishes real lenses from injections}

The 86-percentage-point gap between real-lens recall and injection completeness could in principle arise from the injection parameter space including many undetectable configurations (faint sources, small Einstein radii), rather than from a genuine morphological mismatch.  To test whether the CNN internally distinguishes real from injected lenses \emph{at matched brightness}, we extract the penultimate (1280-dimensional) feature embeddings for 112 real Tier-A lenses, 500 bright ($m_r = 19$) low-$\beta_{\rm frac}$ ($[0.1, 0.3]$) injections configured to produce prominent arcs, and 500 validation negatives.  We emphasise that only brightness is strictly controlled in this comparison; other properties ($\theta_{\rm E}$, PSF, depth, host galaxy type) are not matched to the Tier-A sample.

A logistic regression linear probe trained on the real versus injection embeddings achieves AUC $= 0.996 \pm 0.004$ (five-fold cross-validation).  We note the class imbalance in the probe ($112$ vs $500$ samples); the low fold-to-fold standard deviation ($0.004$) indicates the AUC is stable despite this imbalance.  This near-perfect separation means the CNN has learned features that strongly distinguish injections from real lenses, even when brightness is matched and injections are restricted to high-magnification configurations.  The median CNN score for real Tier-A lenses is 0.995, while injections at the same brightness score a median of 0.110 --- a factor of nine lower.  As a diagnostic of the host-galaxy contribution, we performed a control experiment: a linear probe separating Tier-A (spectroscopically confirmed, $n = 112$) from Tier-B (visual candidates, $n = 500$) lenses, both on their real hosts, using GroupKFold cross-validation by galaxy identifier to prevent leakage of related samples across folds.  This probe achieves AUC $= 0.778 \pm 0.062$ --- moderate separability, indicating that the CNN encodes features that distinguish confirmed from candidate lenses on their real hosts.  However, this does not directly decompose the Tier-A vs injection AUC ($0.996$) into host and morphology components, because Tier-A and Tier-B hosts (massive ellipticals selected by lensing cross-section) differ systematically from injection hosts (random negatives drawn from the full Tractor catalogue).  The substantially higher Tier-A vs injection AUC is \emph{consistent with} injection-specific features (smooth S\'{e}rsic morphology, absence of substructure) contributing additional separation beyond any host confound, but a fully host-matched injection experiment is needed for definitive decomposition (see Section~5.4).

As a complementary check, we computed Fr\'{e}chet distances between real and injection embedding distributions at intermediate feature blocks.  At the earliest block (\texttt{features\_0}, 24-dimensional), the distance is small (0.21), indicating similar low-level statistics.  By the fourth block (\texttt{features\_3}, 160-dimensional), it rises to 63.58, suggesting that the divergence grows through the network hierarchy.  However, deeper layers (blocks 4--7) yield numerically unstable estimates because the sample size ($n = 112$ Tier-A) is smaller than the feature dimensionality, rendering the covariance singular.  We therefore rely on the linear probe AUC as the primary quantitative measure of separability and treat the per-layer Fr\'{e}chet distances as directional rather than definitive.

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{fig2_umap.pdf}
\caption{Two-panel UMAP projection of CNN penultimate-layer (1280-dimensional) embeddings.  \textbf{Left:} Points coloured by category --- real Tier-A (gold), low-$\beta_{\rm frac}$ injections (blue), high-$\beta_{\rm frac}$ injections (cyan), negatives (grey).  \textbf{Right:} Same projection coloured by CNN score ($p$, continuous colourbar from 0 to 1).  UMAP computed with \texttt{n\_neighbors=30}, \texttt{min\_dist=0.3}, \texttt{metric=cosine}, \texttt{random\_state=42}.  Colourbar: \texttt{viridis} (right panel).}
\label{fig:umap}
\end{figure*}

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{fig3_scores.pdf}
\caption{CNN score distributions.  Histograms (50 bins, log-scaled $y$-axis) for: real Tier-A lenses (gold, $n = 112$, median $= 0.995$), low-$\beta_{\rm frac}$ bright injections (blue, $n = 500$, median $= 0.110$), and validation negatives (grey, $n = 500$, median $= 1.5 \times 10^{-5}$).  Vertical lines at $p = 0.3$, 0.806, and 0.995 mark the detection thresholds.}
\label{fig:scores}
\end{figure}

\begin{table}
\caption{Linear probe and feature diagnostics.  Uncertainties ($\pm$) denote the standard deviation across cross-validation folds.  Fr\'{e}chet distances at deeper layers ($\geq$~block~4) are numerically unstable ($n < \mathrm{dim}$) and omitted.}
\label{tab:probe}
\centering
\begin{tabular}{lc}
\toprule
Metric & Value \\
\midrule
Probe AUC: Tier-A vs low-bf inj. & $0.996 \pm 0.004$ (5-fold CV) \\
Probe AUC: Tier-A vs Tier-B (control) & $0.778 \pm 0.062$ (5-fold GroupKFold CV) \\
Fr\'{e}chet distance (features\_0, 24-d) & 0.21 \\
Fr\'{e}chet distance (features\_3, 160-d) & 63.58 (directional only) \\
Median score: real Tier-A & 0.995 \\
Median score: real Tier-B & 0.879 \\
Median score: inj.\ (low-bf, mag 19) & 0.110 \\
Median score: negatives & $1.5 \times 10^{-5}$ \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Testing the noise texture hypothesis}

\subsubsection{Prediction from first principles}
\label{sec:prediction}

If the sim-to-real gap arises from missing noise texture --- smooth S\'{e}rsic arcs lack the pixel-level shot noise of real arcs --- then adding physically correct Poisson noise should make injections more realistic and improve detection.  We can predict the magnitude of this effect from the per-pixel photoelectron budget.

We work through the per-pixel photoelectron budget at three representative lensed magnitudes for a source with $\theta_{\rm E} = 1.5\;\mathrm{arcsec}$ and $\beta_{\rm frac} \approx 0.3$, where the arc spans approximately 90~pixels.  The sky background noise, measured from the annulus MAD, is approximately $0.002\;\mathrm{nmgy\;pixel^{-1}}$.  Using the standard AB relation $f_{\rm nmgy} = 10^{(22.5 - m)/2.5}$:

\begin{itemize}
\item \textbf{Lensed mag 21} ($f_{\rm tot} = 3.98\;\mathrm{nmgy}$): flux per pixel $\approx 0.044\;\mathrm{nmgy}$, giving $6.6\;\mathrm{e^{-}\;pixel^{-1}}$ at gain~$150$.  Poisson $\sigma = 2.6\;\mathrm{e^{-}} = 0.017\;\mathrm{nmgy}$.  Per-pixel SNR drops from $22$ (sky-limited) to $2.6$ (Poisson-dominated).  The arc remains spatially coherent but noticeably noisier.
\item \textbf{Lensed mag 22} ($f_{\rm tot} = 1.58\;\mathrm{nmgy}$): flux per pixel $\approx 0.018\;\mathrm{nmgy}$, giving $2.6\;\mathrm{e^{-}\;pixel^{-1}}$.  Poisson $\sigma = 1.6\;\mathrm{e^{-}} = 0.011\;\mathrm{nmgy}$.  Per-pixel SNR drops from $8.8$ to $1.6$.  The arc's spatial coherence is severely degraded.
\item \textbf{Lensed mag 23} ($f_{\rm tot} = 0.63\;\mathrm{nmgy}$): flux per pixel $\approx 0.007\;\mathrm{nmgy}$, giving $1.05\;\mathrm{e^{-}\;pixel^{-1}}$.  Poisson $\sigma = 1.0\;\mathrm{e^{-}} = 0.007\;\mathrm{nmgy}$ --- comparable to the signal itself.  Per-pixel SNR drops from $3.5$ to $1.0$.  The arc becomes an incoherent scatter of bright and faint pixels.
\end{itemize}

This magnitude range ($22$--$24$) dominates the injection grid volume ($72$~per cent of injections).  The CNN detects lensed arcs as spatially extended, curved features brighter than the local background.  Poisson noise destroys this spatial coherence by adding independent pixel-to-pixel fluctuations comparable to the arc signal.  At smaller Einstein radii, the arc flux is concentrated in fewer pixels (higher flux per pixel, lower fractional Poisson noise), and the effect should be smaller.  At larger Einstein radii, the arc is more extended (lower flux per pixel), and the effect should be larger.

We therefore predict that adding Poisson noise at the DR10 gain should \emph{degrade} detection of arcs at $\theta_{\rm E} \geq 1\;\mathrm{arcsec}$, with the strongest effect in the faint regime ($m_{\rm lensed} \geq 22$) that dominates the grid.  Compact arcs at $\theta_{\rm E} < 1\;\mathrm{arcsec}$ should be less affected.


\subsubsection{Bright-arc controlled experiment}
\label{sec:brightarc}

We test this prediction using a paired experimental design.  For each of 200 host galaxies (selected with fixed seed), we inject lensed sources at eight magnitude bins ($18$--$19$ through $25$--$26$) under six conditions: (1) baseline (no Poisson, clip~$= 10$), (2) Poisson at gain~$= 150$, (3) no Poisson with clip~$= 20$, (4) Poisson with clip~$= 20$, (5) unrestricted $\beta_{\rm frac}$ $[0.1, 1.0]$, and (6) gain~$= 10^{12}$ control.  All controlled conditions (1, 2, 3, 4, 6) use $\beta_{\rm frac} \in [0.1, 0.55]$ and share seed~$= 42$, ensuring each injection uses the same host galaxy and lens/source geometry, with only the noise or preprocessing treatment varying.

Table~\ref{tab:brightarc} presents the full detection-rate matrix.  The baseline detection rate is non-monotonic, peaking at mag~$21$--$22$ ($35.5$~per cent) rather than at the brightest magnitudes ($17.0$~per cent at mag~$18$--$19$).  This is explained by the clip$\,=\,$10 preprocessing: arc pixels brighter than 10 normalised units are truncated to the clip ceiling, collapsing their curved morphology into a flat plateau indistinguishable from saturated artefacts.  The clip$\,=\,$20 results confirm this mechanism, nearly doubling bright-arc detection (mag~$18$--$19$: $17.0 \to 30.5$~per cent).

Poisson noise reduces the detection rate at every magnitude bin with non-trivial sample size.  Across the seven bins with non-tied outcomes (excluding mag~$25$--$26$, where both conditions detect $1.0$~per cent), the Poisson detection rate is lower than baseline in all seven.  A sign test gives $p = 0.5^{7} = 0.0078$, and a Wilcoxon signed-rank test on the paired detection-rate differences gives $W = 28$, $p = 0.008$ (one-sided), both significant at $\alpha = 0.01$.  These tests are performed at the bin level ($n = 7$ paired comparisons) rather than the individual injection level because the aggregated detection-rate JSONs do not store per-injection outcomes.  However, the bin-level tests are conservative: per-injection paired tests (e.g.\ McNemar) on the $7 \times 200 = 1400$ paired outcomes would yield even greater statistical power.

\begin{table*}
\caption{Bright-arc detection rates at $p>0.3$.  All: $\theta_{\rm E}=1.5\;\mathrm{arcsec}$, $N=200$ per mag bin, seed$\,=42$, $\beta_{\rm frac}\in[0.1,0.55]$ unless noted.  The gain~$= 10^{12}$ column matches the baseline at every bin, confirming the Poisson implementation is correct.  Boldface indicates identical values to baseline.}
\label{tab:brightarc}
\centering
\begin{tabular}{lcccccc}
\toprule
Mag bin & Baseline & Poisson ($g\!=\!150$) & clip$\,=\,$20 & Poiss+clip\,20 & Unrestricted$^{a}$ & Gain$\,=\,10^{12}$ \\
\midrule
18--19 & 17.0\% & 14.5\% & 30.5\% & 31.0\% & 17.0\% & \textbf{17.0\%} \\
19--20 & 24.5\% & 18.0\% & 32.0\% & 26.5\% & 21.5\% & \textbf{24.5\%} \\
20--21 & 27.5\% & 25.5\% & 37.0\% & 25.5\% & 28.0\% & \textbf{27.5\%} \\
21--22 & 35.5\% & 33.5\% & 40.5\% & 24.0\% & 20.0\% & \textbf{35.5\%} \\
22--23 & 31.0\% & 29.5\% & 35.0\% & 27.5\% & 17.5\% & \textbf{31.0\%} \\
23--24 & 24.0\% & 17.5\% & 14.5\% &  8.5\% &  7.0\% & \textbf{24.0\%} \\
24--25 &  8.5\% &  6.0\% &  4.5\% &  1.5\% &  4.5\% & \textbf{8.5\%} \\
25--26 &  1.0\% &  1.0\% &  0.0\% &  0.0\% &  0.0\% & \textbf{1.0\%} \\
\bottomrule
\end{tabular}

\medskip
$^{a}$Unrestricted uses $\beta_{\rm frac} \in [0.1, 1.0]$; all other columns use $[0.1, 0.55]$.
\end{table*}

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{fig4_brightarc.pdf}
\caption{Detection rate ($p > 0.3$) versus lensed apparent magnitude for all experimental conditions.  \textbf{Lines:} baseline (blue solid), Poisson gain$\,=\,$150 (orange dashed), clip$\,=\,$20 (green dotted), Poisson + clip\,20 (red dash-dot), unrestricted $\beta_{\rm frac}$ (purple thin solid), gain$\,=\,10^{12}$ control (blue circles, overlaid on baseline).  The gain$\,=\,10^{12}$ line overlays the baseline exactly, providing visual proof that the Poisson implementation is correct.  Error bars: 95~per cent Wilson CIs ($n = 200$).  A horizontal dashed line at $89.3$~per cent marks the Tier-A real-lens recall.  Data from the verified re-evaluation described in Data Availability.}
\label{fig:brightarc}
\end{figure}


\subsubsection{Gain sweep validation}
\label{sec:gainsweep}

To confirm that the Poisson degradation is physical and not a code artifact, we repeated the bright-arc experiment at gain~$= 10^{12}\;\mathrm{e^{-}\;nmgy^{-1}}$, where Poisson noise is negligible ($\sigma \sim 3 \times 10^{-6}\;\mathrm{nmgy\;pixel^{-1}}$).  Detection rates match the no-Poisson baseline at every magnitude bin, every detection threshold, and to within $9.2 \times 10^{-5}$ in median score across all bins.  This confirms three things: (i) the Poisson code path is correct (it adds zero effective noise when the gain is very high), (ii) at gain~$= 150$, the Poisson noise is physically large enough to degrade detection, and (iii) the degradation is not an artifact of gain miscalibration.


\subsubsection{Grid-level confirmation and $\theta_{\rm E}$ dependence}

The bright-arc result generalises to the full parameter-space grid.  Adding Poisson noise at gain~$= 150$ reduces marginal completeness from $3.41$~per cent to $2.37$~per cent ($-1.04$~pp), a highly significant effect (two-proportion $z = 14.6$, $p < 10^{-47}$; 95~per cent CI on difference: $[0.90, 1.18]$~pp).  The deficit is consistent across all five detection thresholds (Table~\ref{tab:thresholds}).

The damage is $\theta_{\rm E}$-dependent, as predicted by the photoelectron budget (Section~\ref{sec:prediction}).  At $\theta_{\rm E} = 0.50\;\mathrm{arcsec}$, completeness increases slightly from $0.44$ to $0.55$~per cent ($z = 1.11$, not significant); at $\theta_{\rm E} = 0.75\;\mathrm{arcsec}$, from $1.22$ to $1.30$~per cent ($z = 0.51$, not significant).  At $\theta_{\rm E} \geq 1.25\;\mathrm{arcsec}$, all differences are statistically significant ($z \geq 4.16$, all $p < 10^{-4}$), with the largest deficit at $\theta_{\rm E} = 2.0\;\mathrm{arcsec}$ ($4.66 \to 2.86$~per cent, $-1.80$~pp, $-38.6$~per cent relative loss).  This pattern confirms that Poisson damage is governed by per-pixel flux: compact arcs at small $\theta_{\rm E}$ concentrate their flux in fewer, brighter pixels where shot noise is a smaller fraction of the signal.


\subsubsection{The Poisson--clipping interaction}

Widening the preprocessing clip range from 10 to 20 preserves bright arc features that would otherwise be clipped, increasing detection at bright magnitudes (e.g.\ $+13.5$~pp at mag~$18$--$19$).  One might expect that combining wider clipping with Poisson noise would yield an intermediate result.  Instead, the interaction is strongly amplified.  At magnitude~$21$--$22$, Poisson noise alone costs $-2.0$~pp (baseline $35.5 \to$ Poisson $33.5$~per cent), while clip$\,=\,$20 alone gains $+5.0$~pp ($35.5 \to 40.5$~per cent).  If these effects were independent, their combination should yield approximately $38.5$~per cent.  The observed value is $24.0$~per cent --- a deficit of $-16.5$~pp below clip$\,=\,$20 alone, representing an $8.2\times$ amplification of the standalone Poisson damage.

The mechanism is that the wider clip range preserves not only bright arc pixels but also Poisson noise peaks that the standard clip would have removed.  The model, trained on clip$\,=\,$10 data, has never seen these noise patterns, creating a double out-of-distribution effect.  This provides additional evidence that the CNN relies on pixel-level texture patterns, not just integrated flux or geometric features.


\subsubsection{Interpretation: the barrier is morphological}

The Poisson noise experiment rules out arc-level shot noise as the dominant missing ingredient.  If smooth injections were unrealistic primarily \emph{because} they lack shot noise, adding noise should improve detection; instead, it worsens it.  This is consistent with a morphological explanation: the smooth spatial coherence of the S\'{e}rsic arc is the only feature that partially matches the CNN's learned arc representations, and Poisson noise disrupts even that.  The gain sweep confirms the degradation is physical.  We note that the observed degradation has two contributing components: a physical component (Poisson noise objectively reduces per-pixel SNR, as demonstrated by the photoelectron budget in Section~\ref{sec:prediction}) and a distributional component (the model was not trained on Poisson-noised arcs, so the added noise is out-of-distribution).  The gain sweep confirms the physical component but cannot fully separate the two.  Furthermore, this test addresses one specific class of texture mismatch (independent arc shot noise); other texture mismatches (correlated coadd noise, inter-band noise correlations, PSF wing structure) remain untested.

Real lensed arcs at the same brightness \emph{also} experience Poisson noise, yet remain highly detectable (median score 0.995).  The difference is that real arcs possess spatially coherent substructure --- star-forming clumps, caustic crossings, multiple-image components --- that survives Poisson noise because these features have intrinsically higher contrast than the smooth S\'{e}rsic envelope.  The smooth S\'{e}rsic model has no such features; when Poisson noise is added, its coherent arc curve is disrupted with nothing to compensate.

We conclude that the dominant barrier to realistic injection-recovery is consistent with a \emph{morphological} shortfall: parametric S\'{e}rsic profiles lack the spatial complexity of real lensed galaxies.  The injection completeness should therefore be interpreted as a lower bound on the true selection function, under the assumption that parametric injections are at least as difficult for the CNN to detect as real lenses of the same physical parameters (see Section~5.3 for caveats).


% ====================================================================
% 5. DISCUSSION
% ====================================================================
\section{Discussion}

\subsection{Comparison with published results}

\begin{table*}
\caption{Comparison with published CNN strong lens finder results.}
\label{tab:published}
\centering
\begin{tabular}{llllll}
\toprule
Study & Survey & Architecture & Source model & Recall / Completeness & Realism test \\
\midrule
This work & DESI DR10 & EfficientNetV2-S & S\'{e}rsic + clumps & 89.3\% / 3.41\% & Probe AUC $= 0.996$ \\
\citet{Herle2024} & Euclid sim & Multiple CNNs & Parametric S\'{e}rsic & N/A (simulated) & None \\
\citet{Canameras2024} & HSC PDR2 & CNN ensemble & Real HUDF stamps & TPR$_0$ 10--40\% & N/A (real stamps) \\
\citet{EuclidPrepXXXIII} & Euclid sim & CNN/Inception/ResNet & Parametric & 75--90\% & None \\
\citet{Huang2020} & DECaLS & ResNet & N/A & No completeness & None \\
\citet{Jacobs2019} & DES & CNN & Parametric & $\sim$50\% bright arcs & None \\
\bottomrule
\end{tabular}
\end{table*}

\citet{Herle2024} characterised how CNN selection functions depend on lens and source properties (Einstein radius, S\'{e}rsic index, source size), working entirely in simulation.  Our work provides the complementary measurement: not just that selection is biased, but that parametric injections are morphologically distinguishable from real lenses in CNN feature space.  Together, the two results establish that parametric injection-based selection functions are both biased and unreliable unless realism-validated.

\citet{Canameras2024} (HOLISMOKES~XI) sidestep the parametric limitation by using real galaxy stamps from the HUDF as source-plane objects for injection into HSC imaging.  Their approach avoids the morphological barrier we identify, supporting our conclusion that the barrier is a property of the parametric source model rather than the injection-recovery framework itself.

We caution against comparing absolute completeness numbers across studies.  Our marginal completeness of $3.41$~per cent covers the full parameter space including many configurations that produce faint or unresolvable arcs ($72$~per cent of injections land at lensed magnitude $>22$).  The high completeness reported by \citet{EuclidPrepXXXIII} reflects pre-selected high-contrast configurations in fully synthetic data, without the real-survey artefacts and the sim-to-real gap that we quantify here.

\subsection{The linear probe as a realism gate}

We propose the linear probe AUC as a quantitative realism gate for injection pipelines.  A pipeline whose injections are indistinguishable from real lenses in CNN feature space should yield a linear probe AUC near 0.5 (chance level).  Our measured AUC of $0.996$ indicates near-perfect distinguishability, confirming that parametric S\'{e}rsic injections fail this gate decisively.

We suggest that an AUC below approximately 0.7 would indicate that injection morphology is realistic enough for unbiased completeness estimation.  This threshold is provisional and should be calibrated against completeness measurements that agree between injection types.  The key insight is that the linear probe provides a cheap, architecture-internal diagnostic that does not require ground truth about the true selection function.  Any injection pipeline can be tested against the target survey's confirmed lenses using only a pre-trained model and a set of real positive examples.

\subsection{Implications for lens population studies}

Our completeness map $C(\theta_{\rm E}, \mathrm{PSF}, \mathrm{depth})$ is best interpreted as a lower bound on the true selection function, under the assumption that parametric injections are at least as difficult for the CNN to detect as real lenses of the same physical parameters.  The linear probe result (AUC $= 0.996$, with real lenses scoring systematically higher than injections) supports this assumption, but we cannot rigorously prove it holds in every cell of the parameter space.  Population studies using these completeness values should treat them as approximate lower bounds rather than unbiased estimates.

For population studies that require upper limits on lens number counts, this lower bound is directly useful: $N_{\rm lens} \leq N_{\rm observed} / C$.  For studies requiring unbiased completeness estimates (e.g.\ for the lens mass function), the completeness map should be used with caution until the injection realism gap is closed.

\subsection{Limitations}

Several limitations of this analysis should be noted.

First, our results are based on a single CNN architecture (EfficientNetV2-S).  However, the morphological barrier we identify is a property of the injected sources, not the classifier.  The per-pixel photoelectron analysis (Section~\ref{sec:prediction}) depends only on the survey gain and source flux.  The linear probe separation occurs at mid-level CNN features (Section~4.3) corresponding to texture and shape --- properties that any vision model with sufficient capacity would encode.  Testing additional architectures (e.g.\ Vision Transformers) is a useful cross-check but is unlikely to alter the fundamental conclusion that parametric S\'{e}rsic sources lack the morphological complexity of real lensed galaxies.

Second, our Poisson noise test targets a specific class of texture mismatch --- missing arc shot noise --- because the host and background already come from real DR10 cutouts.  We do not claim to have ruled out all texture mismatches.  In particular, we do not model correlated noise in the coadd imaging.  Real coadds have spatially correlated noise from the dithering and resampling process, which has a fundamentally different spatial structure from independent shot noise.  While independent Poisson noise disrupts spatial coherence pixel-by-pixel, correlated noise creates spatially coherent fluctuations that could in principle make injections look more like real survey features rather than less.  The effect of correlated coadd noise on injection detectability is therefore an open question that cannot be inferred from the independent-noise result.

Third, the injection pipeline uses a single $r$-band PSF FWHM scaled by fixed factors for $g$ and $z$, rather than band-dependent PSFs from the imaging metadata.  Real observations exhibit chromatic seeing variation of $10$--$20$~per cent between bands.  This limitation is shared by most published injection-recovery analyses for ground-based surveys \citep{Herle2024}.  The effect is small compared to the morphological gap we identify.

Fourth, the annulus normalisation radii $(20, 32)$~pixels are suboptimal for $101 \times 101$ stamps (Appendix~\ref{app:annulus}).  This produces a $0.15$-normalised-unit additive offset but does not affect the MAD or the relative comparison between real and injected lenses, both of which are processed through the same normalisation.

Fifth, the training positive class includes Tier-B lenses with an estimated $\sim\!10$~per cent label noise rate.  If some Tier-B positives are not genuine lenses, the model may have learned features of non-lens contaminants as ``positive'' signatures, potentially affecting the linear probe results.  However, our headline metrics are evaluated exclusively on Tier-A (spectroscopically confirmed) lenses, limiting this concern to the training representation rather than the evaluation.

Sixth, our Tier-A sample contains only 112 lenses, yielding a 95~per cent confidence interval spanning approximately 11~percentage points on the recall.  Forthcoming spectroscopic campaigns (DESI, 4MOST) will expand the confirmed lens sample by an order of magnitude, enabling significantly tighter constraints.

Seventh, the linear probe comparison (Section~4.3) uses real Tier-A lenses on their native host galaxies versus injections placed on random validation negatives.  The host galaxy populations differ: real lens hosts are massive ellipticals selected by their lensing cross-section, while injection hosts are drawn from the full negative population.  As a partial diagnostic, we performed a Tier-A vs Tier-B control probe (both on real hosts), obtaining AUC $= 0.778 \pm 0.062$ (GroupKFold by galaxy identifier).  This indicates that the CNN encodes features that distinguish confirmed from candidate lenses within the real population, and the substantially higher Tier-A vs injection AUC ($0.996$) is consistent with injection-specific features contributing additional separation.  However, the Tier-A vs Tier-B probe does not directly decompose the injection AUC into host and morphology components, because both Tier-A and Tier-B share lens-type hosts that differ systematically from the random negatives used as injection hosts.  A fully host-matched injection experiment (matching hosts by colour, size, and surface brightness) would provide a definitive decomposition.

Eighth, the Poisson noise draws use PyTorch's global random state rather than a per-injection seeded generator (a limitation of \texttt{torch.poisson}), making Poisson results not exactly reproducible across different execution environments even with the same explicit seed.  This explains the minor discrepancy between our initial run ($2.35$~per cent) and an independent replication ($2.37$~per cent) of Poisson grid completeness, while all non-Poisson results reproduce exactly.


\subsection{Future directions}

The natural next step is to replace parametric S\'{e}rsic sources with real galaxy stamps from deep imaging.  \citet{Canameras2024} demonstrated this approach for HSC using HUDF stamps.  Adapting their procedure to DESI DR10 requires careful treatment of the HST-to-DESI bandpass transformation, the $8.7\times$ pixel scale difference (HUDF at $0.03\;\mathrm{arcsec\;pixel^{-1}}$ versus DESI at $0.262\;\mathrm{arcsec\;pixel^{-1}}$), and PSF matching.  We propose using the linear probe AUC as a quantitative gate: when real-stamp injections achieve AUC below $\sim\! 0.7$, their completeness estimates can be considered reliable.  This threshold and the real-stamp pipeline are subjects of forthcoming work.

Additional improvements to the injection pipeline include implementing band-dependent PSF convolution, modelling correlated noise from the coadd process, and extending the source prior to include multi-component lensed morphologies (e.g.\ multiple merging images, Einstein rings).


% ====================================================================
% 6. CONCLUSIONS
% ====================================================================
\section{Conclusions}

We have presented a comprehensive analysis of the selection function for a CNN strong gravitational lens finder applied to DESI Legacy Imaging Survey DR10.  Our main results are as follows.

\begin{enumerate}
\item[(i)] The EfficientNetV2-S classifier achieves $89.3$~per cent recall (95~per cent CI: $[82.6, 94.0]$~per cent) on 112 spectroscopically confirmed Tier-A lenses, with zero Tier-A HEALPix pixel overlap between training and validation sets.

\item[(ii)] Standard injection-recovery with parametric S\'{e}rsic source profiles yields a marginal completeness of only $3.41$~per cent ($3755 / 110\,000$) over the full parameter space.  Even for brightness-matched injections at lensed magnitude $20$--$22$, completeness is $20.7$~per cent --- less than a quarter of the Tier-A recall --- and a linear probe indicates that the gap extends beyond photometric differences, consistent with a morphological mismatch between parametric injections and real lensed galaxies.

\item[(iii)] A linear probe in the CNN's penultimate feature space separates real lenses from brightness-matched injections with AUC $= 0.996 \pm 0.004$, establishing that the CNN has learned to distinguish them based on properties beyond brightness alone.

\item[(iv)] Adding arc-level Poisson noise to injections \emph{degrades} detection (from $3.41$ to $2.37$~per cent, $z = 14.6$, $p < 10^{-47}$), ruling out missing arc shot noise as the dominant cause of the realism gap.  A gain sweep control at $10^{12}\;\mathrm{e^{-}\;nmgy^{-1}}$ recovers the no-noise baseline exactly, confirming the result is physical.  The damage is $\theta_{\rm E}$-dependent, as predicted by the per-pixel photoelectron budget: negligible below $1.0\;\mathrm{arcsec}$, statistically significant above $1.25\;\mathrm{arcsec}$, peaking at $2.0\;\mathrm{arcsec}$ ($-38.6$~per cent relative loss).

\item[(v)] The injection realism gap is consistent with a \emph{morphological barrier}: parametric S\'{e}rsic profiles lack the spatially coherent substructure of real lensed galaxies.  The injection completeness map $C(\theta_{\rm E}, \mathrm{PSF}, \mathrm{depth})$ should be interpreted as completeness for the specific parametric injection family, not as an unbiased estimate of the true survey selection function.  We propose the linear probe AUC as a quantitative realism gate for the community to evaluate and compare injection pipelines.
\end{enumerate}


\section*{Acknowledgements}
[Acknowledgements to be added.]

\section*{Data availability}
The injection pipeline code, selection function grid, and bright-arc test results will be made available at [repository URL] upon publication.  The DESI Legacy Imaging Survey DR10 data are publicly available at \url{https://www.legacysurvey.org/dr10/}.


% ====================================================================
% REFERENCES
% ====================================================================
\begin{thebibliography}{99}
\bibitem[\protect\citeauthoryear{Ca\~{n}ameras et al.}{2021}]{Canameras2021} Ca\~{n}ameras R. et al., 2021, A\&A, 653, L6
\bibitem[\protect\citeauthoryear{Ca\~{n}ameras et al.}{2024}]{Canameras2024} Ca\~{n}ameras R. et al., 2024, A\&A, 689, A280 (HOLISMOKES~XI)
\bibitem[\protect\citeauthoryear{Ciotti \& Bertin}{1999}]{CiottiBertin1999} Ciotti L., Bertin G., 1999, A\&A, 352, 447
\bibitem[\protect\citeauthoryear{Collett}{2015}]{Collett2015} Collett T.~E., 2015, ApJ, 811, 20
\bibitem[\protect\citeauthoryear{Collett \& Cunnington}{2022}]{CollettCunnington2022} Collett T.~E., Cunnington S., 2022, MNRAS, 516, 1808
\bibitem[\protect\citeauthoryear{Dey et al.}{2019}]{Dey2019} Dey A. et al., 2019, AJ, 157, 168
\bibitem[\protect\citeauthoryear{Euclid Collaboration}{2024}]{EuclidPrepXXXIII} Euclid Collaboration et al., 2024, A\&A, 690, A240 (Euclid Prep.~XXXIII)
\bibitem[\protect\citeauthoryear{Gavazzi et al.}{2014}]{Gavazzi2014} Gavazzi R. et al., 2014, ApJ, 785, 144
\bibitem[\protect\citeauthoryear{Graham \& Driver}{2005}]{GrahamDriver2005} Graham A.~W., Driver S.~P., 2005, PASA, 22, 118
\bibitem[\protect\citeauthoryear{Herle et al.}{2024}]{Herle2024} Herle A. et al., 2024, MNRAS, 534, 1093
\bibitem[\protect\citeauthoryear{Huang et al.}{2020}]{Huang2020} Huang X. et al., 2020, ApJ, 894, 78
\bibitem[\protect\citeauthoryear{Jacobs et al.}{2019}]{Jacobs2019} Jacobs C. et al., 2019, ApJS, 243, 17
\bibitem[\protect\citeauthoryear{Keeton}{2001}]{Keeton2001} Keeton C.~R., 2001, preprint (astro-ph/0102341)
\bibitem[\protect\citeauthoryear{Kormann, Schneider \& Bartelmann}{1994}]{Kormann1994} Kormann R., Schneider P., Bartelmann M., 1994, A\&A, 284, 285
\bibitem[\protect\citeauthoryear{Lanusse et al.}{2018}]{Lanusse2018} Lanusse F. et al., 2018, MNRAS, 473, 3895
\bibitem[\protect\citeauthoryear{Metcalf et al.}{2019}]{Metcalf2019} Metcalf R.~B. et al., 2019, A\&A, 625, A119
\bibitem[\protect\citeauthoryear{Petrillo et al.}{2017}]{Petrillo2017} Petrillo C.~E. et al., 2017, MNRAS, 472, 1129
\bibitem[\protect\citeauthoryear{Rojas et al.}{2022}]{Rojas2022} Rojas K. et al., 2022, A\&A, 668, A73
\bibitem[\protect\citeauthoryear{Savary et al.}{2022}]{Savary2022} Savary E. et al., 2022, A\&A, 666, A1
\bibitem[\protect\citeauthoryear{S\'{e}rsic}{1968}]{Sersic1968} S\'{e}rsic J.~L., 1968, Atlas de Galaxias Australes. Obs.\ Astron\'{o}mico, C\'{o}rdoba
\bibitem[\protect\citeauthoryear{Sonnenfeld}{2022}]{Sonnenfeld2022} Sonnenfeld A., 2022, A\&A, 659, A132
\bibitem[\protect\citeauthoryear{Stein et al.}{2022}]{Stein2022} Stein G. et al., 2022, ApJ, 932, 107
\bibitem[\protect\citeauthoryear{Storfer et al.}{2024}]{Storfer2024} Storfer C. et al., 2024, ApJ, 960, 54
\bibitem[\protect\citeauthoryear{Tan \& Le}{2021}]{TanLe2021} Tan M., Le Q.~V., 2021, in Proc.\ ICML, pp.\ 10096--10106
\bibitem[\protect\citeauthoryear{Treu}{2010}]{Treu2010} Treu T., 2010, ARA\&A, 48, 87
\end{thebibliography}


% ====================================================================
% APPENDIX
% ====================================================================
\appendix
\section{Annulus normalisation characterisation}
\label{app:annulus}

The \texttt{raw\_robust} preprocessing normalises each band using the median and MAD of an outer annulus.  The annulus radii used during training ($r_{\rm in} = 20$, $r_{\rm out} = 32$~pixels) were originally calibrated for $64 \times 64$ stamps.  For the $101 \times 101$ stamps used in this work, the geometrically optimal radii are approximately $(32.5, 45.0)$~pixels.

We characterise the impact of this discrepancy through four diagnostic experiments on validation-split cutouts.

\textbf{Normalisation statistics} ($n = 1000$).  The old annulus yields a median offset of $+0.000345\;\mathrm{nmgy}$ relative to the corrected annulus, corresponding to $0.15$ normalised units ($1.5$~per cent of the clip range).  The MAD is unchanged (KS test $p = 0.648$).  The offset shows no correlation with PSF FWHM ($r = -0.025$, $p = 0.43$) or depth ($r = 0.026$, $p = 0.42$).

\textbf{Mismatched scoring} ($n = 500$ positives $+ 500$ negatives).  Scoring validation cutouts with the corrected annulus (mismatched to the training annulus) yields a recall drop of $3.6$~pp at $p > 0.3$ ($z = 1.27$, $p = 0.10$, not significant).  This is consistent with the expected sensitivity of any neural network to changes in its input distribution.

\textbf{Split balance.}  Two-sample KS tests confirm that PSF FWHM ($p = 0.174$) and depth ($p = 0.123$) distributions are balanced between training and validation splits, ensuring the annulus discrepancy affects both sets equally.

\textbf{Spatial integrity.}  Recomputed HEALPix assignments confirm zero Tier-A spatial overlap between training and validation sets (274 and 112 unique pixels, respectively).

We conclude that the annulus discrepancy is cosmetic for model performance.  It does not bias the relative comparison between real and injected lenses (both are processed through the same normalisation), and it does not introduce condition-dependent distortions across the survey footprint.  We retain the training-consistent annulus for all analyses in this paper.


\bsp
\label{lastpage}
\end{document}
